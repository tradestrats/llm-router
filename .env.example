# LLM Router Environment Configuration
# Copy this file to .env and fill in your actual values

# Required: Get your API key from https://openrouter.ai/keys
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Optional: Override default models (comma-separated)
# LLM_MODELS=meta-llama/llama-3.2-3b-instruct:free,google/gemma-2-9b-it:free

# Optional: Server configuration
# PORT=8080
# HOST=0.0.0.0

# Optional: Bandit algorithm tuning
# FEEDBACK_WEIGHT=0.6        # How much user feedback influences selection (0-1)
# LATENCY_WEIGHT=0.2         # How much response speed matters (positive values)
# COST_WEIGHT=-0.2           # How much cost matters (negative values)
# EXPLORATION_RATE=0.15      # How often to try non-optimal models (0-1)
# SIMILARITY_THRESHOLD=0.7   # How similar requests must be to reuse learnings (0-1)

# Optional: Database configuration (for persistence)
# ENABLE_PERSISTENCE=false
# DATABASE_URL=postgresql://user:password@localhost:5432/llm-router
# DATABASE_HOST=localhost
# DATABASE_PORT=5432
# DATABASE_USER=llm-router
# DATABASE_PASSWORD=your_db_password
# DATABASE_NAME=llm-router

# Optional: Logging configuration
# LOG_LEVEL=info            # debug, info, warn, error
# LOG_FORMAT=auto           # json, text, auto