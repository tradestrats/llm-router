server:
  host: "0.0.0.0"
  port: "8080"
  app_name: "LLM Router"
  referer_url: "https://llm-router.ai"
  cors_origins: ["*"]

llm_provider:
  api_key: "${OPENROUTER_API_KEY}"
  base_url: "https://openrouter.ai/api/v1"
  allowed_models:
    # Free models from OpenRouter
    - "meta-llama/llama-3.2-3b-instruct:free"
    - "meta-llama/llama-3.2-1b-instruct:free"
    - "google/gemma-2-9b-it:free"
    - "microsoft/phi-3-mini-128k-instruct:free"
    - "microsoft/phi-3-medium-128k-instruct:free"
    - "qwen/qwen-2-7b-instruct:free"
    - "huggingfaceh4/zephyr-7b-beta:free"
    - "openchat/openchat-7b:free"
    # Premium models (require credits)
    - "anthropic/claude-3.5-sonnet"
    - "openai/gpt-4o"

bandit:
  default_model: "meta-llama/llama-3.2-3b-instruct:free"
  thompson_sampling:
    feedback_weight: 0.6
    latency_weight: 0.2
    cost_weight: -0.2
    exploration_rate: 0.15
  similarity:
    threshold: 0.7
    max_similar_requests: 50
    recency_days: 30
    min_similar_requests: 5
  cold_start:
    min_confidence_score: 0.1
    optimistic_prior: 0.8
    exploration_bonus: 0.1
    min_requests_for_global: 10
  persistence:
    batch_size: 100

embedding:
  service_type: "http"
  service_url: "http://localhost:8001"
  model_path: "./models/all-MiniLM-L6-v2"
  max_workers: 4
  cache_size: 1000
  timeout_ms: 5000

database:
  enable_persistence: true
  url: "${DATABASE_URL}"
  host: "${DATABASE_HOST:-localhost}"
  port: "${DATABASE_PORT:-5432}"
  user: "${DATABASE_USER:-llm-proxy}"
  password: "${DATABASE_PASSWORD}"
  name: "${DATABASE_NAME:-llm-proxy}"
  ssl_mode: "${DATABASE_SSL_MODE:-disable}"
  workers: 5
  buffer_size: 1000

circuit_breaker:
  enabled: true
  failure_threshold: 5
  success_threshold: 2
  timeout: 60s
  max_requests: 3

logging:
  level: "info"
  format: "auto"
  report_caller: false