# OpenRouter API Configuration
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Server Configuration
PORT=8080
HOST=0.0.0.0

# Available LLM Models (comma-separated)
LLM_MODELS=meta-llama/llama-3.2-3b-instruct:free,google/gemma-2-9b-it:free,microsoft/phi-3-mini-128k-instruct:free

# Default Model for contextual routing
DEFAULT_MODEL=meta-llama/llama-3.2-3b-instruct:free

# CORS Configuration (comma-separated origins, use * for all)
CORS_ORIGINS=*

# Application Identity
REFERER_URL=https://llm-proxy.com
APP_NAME=LLM-Proxy

# Database operation batching
BATCH_SIZE=100

# Logging
LOG_LEVEL=info
# Environment name: development|production
ENV=development
# Log format: auto|json|text (auto=json in production, text otherwise)
LOG_FORMAT=auto
# Include caller (file:line) in logs
LOG_REPORT_CALLER=false
